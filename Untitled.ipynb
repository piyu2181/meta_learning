{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "############Import required functions##########################################\n",
    "\n",
    "class MAMLModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MAMLModel, self).__init__()\n",
    "        self.model = nn.Sequential(OrderedDict([\n",
    "            ('l1', nn.Linear(1,40)),\n",
    "            ('relu1', nn.ReLU())\n",
    "        ]))\n",
    "        self.modela = nn.Sequential(OrderedDict([\n",
    "            ('l2a', nn.Linear(40,40)),\n",
    "            ('relu2a', nn.ReLU()),\n",
    "            ('l3a', nn.Linear(40,1))\n",
    "        ]))\n",
    "        self.modelb = nn.Sequential(OrderedDict([\n",
    "            ('l2b', nn.Linear(40,40)),\n",
    "            ('relu2b', nn.ReLU()),\n",
    "            ('l3b', nn.Linear(40,1))\n",
    "        ]))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.modela(self.model(x)), self.modelb(self.model(x))\n",
    "    \n",
    "    def parameterised(self, x, weights):\n",
    "        # like forward, but uses ``weights`` instead of ``model.parameters()``\n",
    "        # it'd be nice if this could be generated automatically for any nn.Module...\n",
    "        x = nn.functional.linear(x, weights[0], weights[1])\n",
    "        x = nn.functional.relu(x)\n",
    "        xa = nn.functional.linear(x, weights[2], weights[3])\n",
    "        xa = nn.functional.relu(xa)\n",
    "        xa = nn.functional.linear(xa, weights[4], weights[5])\n",
    "        xb = nn.functional.linear(x, weights[6], weights[7])\n",
    "        xb = nn.functional.relu(xb)\n",
    "        xb = nn.functional.linear(xb, weights[8], weights[9])\n",
    "        return xa, xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "\n",
    "############Import required functions##########################################\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "############Import required functions##########################################\n",
    "class MAML():\n",
    "    def __init__(self, model, tasks, inner_lr, meta_lr, K=30, inner_steps=1, tasks_per_meta_batch=1000):\n",
    "        \n",
    "        # important objects\n",
    "        self.tasks = tasks\n",
    "        self.model = model\n",
    "        # Puting model on gpu if available\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        self.weights = list(model.parameters())\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.meta_optimiser = torch.optim.Adam(self.weights, meta_lr)\n",
    "    \n",
    "        \n",
    "        # hyperparameters\n",
    "        self.inner_lr = inner_lr\n",
    "        self.meta_lr = meta_lr\n",
    "        self.K = K\n",
    "        self.inner_steps = inner_steps \n",
    "        self.tasks_per_meta_batch = tasks_per_meta_batch \n",
    "        \n",
    "        # metrics\n",
    "        self.plot_every = 5\n",
    "        self.print_every = 5\n",
    "        self.meta_losses = []\n",
    "        self.meta_mean_losses = []\n",
    "        self.meta_sigma_losses = []\n",
    "    \n",
    "    def inner_loop(self, task):\n",
    "        # reset inner model to current maml weights\n",
    "        temp_weights = [w.clone() for w in self.weights]\n",
    "        \n",
    "        # perform training on data sampled from task\n",
    "        X, y = task.sample_data(True,self.K)\n",
    "        #y_noise = (y2 - y)\n",
    "        X = X.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "        #y2 = y2.to(self.device)\n",
    "        #y_noise = y_noise.to(self.device)\n",
    "        for step in range(self.inner_steps):\n",
    "            #print((self.model.parameterised(X, temp_weights)[1]).shape)\n",
    "            #print(\"I m here\")\n",
    "            mean_loss = self.criterion(self.model.parameterised(X, temp_weights)[0], y) / self.K # kind of training loss\n",
    "            sigma_loss = self.criterion(self.model.parameterised(X, temp_weights)[1] , torch.abs(y - self.model.parameterised(X, temp_weights)[0])) / self.K # kind of training loss\n",
    "            final_loss = (mean_loss + sigma_loss)\n",
    "            \n",
    "            # compute grad and update inner loop weights\n",
    "            grad =torch.autograd.grad(final_loss, temp_weights)\n",
    "            #grad_noise =torch.autograd.grad(noise_loss, temp_noise_weights)\n",
    "            temp_weights = [w - self.inner_lr * g for w, g in zip(temp_weights, grad)]\n",
    "            \n",
    "        \n",
    "        #sample new data for meta-update and compute loss\n",
    "        X, y =  task.sample_data(True, self.K)\n",
    "       # y_noise = (y2 - y)\n",
    "        X = X.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "        #y2 = y2.to(self.device)\n",
    "        #y_noise = y_noise.to(self.device)\n",
    "       #print(\"y_noise:\", y_noise.shape)\n",
    "        mean_loss = self.criterion(self.model.parameterised(X, temp_weights)[0], y) / self.K # kind of training loss\n",
    "        sigma_loss = self.criterion(self.model.parameterised(X, temp_weights)[1] , torch.abs(y - self.model.parameterised(X, temp_weights)[0])) / self.K\n",
    "        final_loss = mean_loss + sigma_loss\n",
    "        return (final_loss, mean_loss.item(), sigma_loss.item())\n",
    "    \n",
    "    def main_loop(self, num_iterations):\n",
    "        epoch_loss = 0\n",
    "        epoch_mean_loss = 0\n",
    "        epoch_sigma_loss = 0\n",
    "        \n",
    "        for iteration in range(1, num_iterations+1):\n",
    "            \n",
    "            # compute meta loss\n",
    "            meta_loss = 0\n",
    "            meta_mean_loss = 0\n",
    "            meta_sigma_loss = 0\n",
    "            \n",
    "            for i in range(self.tasks_per_meta_batch):\n",
    "                task = self.tasks.sample_task()\n",
    "                a,b,c = self.inner_loop(task)\n",
    "                meta_loss += a\n",
    "                meta_mean_loss += b\n",
    "                meta_sigma_loss += c\n",
    "            \n",
    "            # compute meta gradient of loss with respect to maml weights\n",
    "            meta_grads = torch.autograd.grad(meta_loss, self.weights)\n",
    "            \n",
    "            # assign meta gradient to weights and take optimisation step\n",
    "            for w, g in zip(self.weights, meta_grads):\n",
    "                w.grad = g\n",
    "            self.meta_optimiser.step()\n",
    "            \n",
    "            \n",
    "            # log metrics\n",
    "            epoch_loss += meta_loss.item() / self.tasks_per_meta_batch\n",
    "            epoch_mean_loss += meta_mean_loss / self.tasks_per_meta_batch\n",
    "            epoch_sigma_loss += meta_sigma_loss / self.tasks_per_meta_batch\n",
    "            \n",
    "            if iteration % self.print_every == 0:\n",
    "                print(\"{}/{}. loss: {}\".format(iteration, num_iterations, epoch_loss / self.plot_every))\n",
    "                print(\"{}/{}. y_loss: {}\".format(iteration, num_iterations, epoch_mean_loss / self.plot_every))\n",
    "                print(\"{}/{}. noise_loss: {}\".format(iteration, num_iterations, epoch_sigma_loss / self.plot_every))\n",
    "                \n",
    "            \n",
    "            if iteration % self.plot_every == 0:\n",
    "                self.meta_losses.append(epoch_loss / self.plot_every)\n",
    "                self.meta_mean_losses.append(epoch_mean_loss / self.plot_every)\n",
    "                self.meta_sigma_losses.append(epoch_sigma_loss / self.plot_every)\n",
    "                epoch_loss = 0\n",
    "                epoch_mean_loss = 0\n",
    "                epoch_sigma_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/10000. loss: 0.4407075622558594\n",
      "5/10000. y_loss: 0.2309282738971524\n",
      "5/10000. noise_loss: 0.20977933550585295\n",
      "10/10000. loss: 0.39687709350585937\n",
      "10/10000. y_loss: 0.22014662838004298\n",
      "10/10000. noise_loss: 0.17673051777255025\n",
      "15/10000. loss: 0.37053208618164063\n",
      "15/10000. y_loss: 0.2161868543075427\n",
      "15/10000. noise_loss: 0.15434524910601322\n",
      "20/10000. loss: 0.3653948364257813\n",
      "20/10000. y_loss: 0.22141700086892815\n",
      "20/10000. noise_loss: 0.1439776853163261\n",
      "25/10000. loss: 0.3650126037597656\n",
      "25/10000. y_loss: 0.22675484180497008\n",
      "25/10000. noise_loss: 0.13825779327200727\n",
      "30/10000. loss: 0.34609348754882807\n",
      "30/10000. y_loss: 0.21802871153541345\n",
      "30/10000. noise_loss: 0.1280648700384423\n",
      "35/10000. loss: 0.3572537536621094\n",
      "35/10000. y_loss: 0.22471961892640682\n",
      "35/10000. noise_loss: 0.1325341299958527\n",
      "40/10000. loss: 0.34173215332031254\n",
      "40/10000. y_loss: 0.2168102829143012\n",
      "40/10000. noise_loss: 0.12492186211533843\n",
      "45/10000. loss: 0.327935595703125\n",
      "45/10000. y_loss: 0.20983465414918903\n",
      "45/10000. noise_loss: 0.11810093253068625\n",
      "50/10000. loss: 0.3387210632324219\n",
      "50/10000. y_loss: 0.2175426973774724\n",
      "50/10000. noise_loss: 0.12117836756519973\n",
      "55/10000. loss: 0.35391708984375\n",
      "55/10000. y_loss: 0.22684769125918686\n",
      "55/10000. noise_loss: 0.12706947240792216\n",
      "60/10000. loss: 0.3318427490234375\n",
      "60/10000. y_loss: 0.21389280295365315\n",
      "60/10000. noise_loss: 0.1179499513056129\n",
      "65/10000. loss: 0.3328808715820312\n",
      "65/10000. y_loss: 0.21573687157814855\n",
      "65/10000. noise_loss: 0.1171440021342598\n",
      "70/10000. loss: 0.3535085327148438\n",
      "70/10000. y_loss: 0.22707329162557724\n",
      "70/10000. noise_loss: 0.12643536214232448\n",
      "75/10000. loss: 0.33382791137695317\n",
      "75/10000. y_loss: 0.21695538708585663\n",
      "75/10000. noise_loss: 0.11687259111488238\n",
      "80/10000. loss: 0.3442797912597656\n",
      "80/10000. y_loss: 0.22332590366591173\n",
      "80/10000. noise_loss: 0.12095370202790945\n",
      "85/10000. loss: 0.3248894287109375\n",
      "85/10000. y_loss: 0.21161209366700207\n",
      "85/10000. noise_loss: 0.11327734676115216\n",
      "90/10000. loss: 0.3338023193359375\n",
      "90/10000. y_loss: 0.2189612613801728\n",
      "90/10000. noise_loss: 0.11484096381440759\n",
      "95/10000. loss: 0.32681967163085934\n",
      "95/10000. y_loss: 0.21379984956206463\n",
      "95/10000. noise_loss: 0.11301979580195623\n",
      "100/10000. loss: 0.32337296142578126\n",
      "100/10000. y_loss: 0.21192750716327863\n",
      "100/10000. noise_loss: 0.11144542439896613\n",
      "105/10000. loss: 0.3225990600585938\n",
      "105/10000. y_loss: 0.21208490272577038\n",
      "105/10000. noise_loss: 0.11051431643711404\n",
      "110/10000. loss: 0.31612472534179686\n",
      "110/10000. y_loss: 0.20797226529857724\n",
      "110/10000. noise_loss: 0.10815251214420422\n",
      "115/10000. loss: 0.31692314453125\n",
      "115/10000. y_loss: 0.20795783846663546\n",
      "115/10000. noise_loss: 0.10896544468589127\n",
      "120/10000. loss: 0.3197973571777344\n",
      "120/10000. y_loss: 0.20940764156591612\n",
      "120/10000. noise_loss: 0.11038960743919016\n",
      "125/10000. loss: 0.31999027709960937\n",
      "125/10000. y_loss: 0.2105997165426612\n",
      "125/10000. noise_loss: 0.10939051845055074\n",
      "130/10000. loss: 0.31933544921875\n",
      "130/10000. y_loss: 0.2099194039763475\n",
      "130/10000. noise_loss: 0.1094160948831588\n",
      "135/10000. loss: 0.3193344909667969\n",
      "135/10000. y_loss: 0.2090711268882849\n",
      "135/10000. noise_loss: 0.11026340219676496\n",
      "140/10000. loss: 0.3135095031738281\n",
      "140/10000. y_loss: 0.2053397284820472\n",
      "140/10000. noise_loss: 0.1081697366926819\n",
      "145/10000. loss: 0.30242067871093753\n",
      "145/10000. y_loss: 0.19849082444856178\n",
      "145/10000. noise_loss: 0.1039299161929637\n",
      "150/10000. loss: 0.2976323486328125\n",
      "150/10000. y_loss: 0.19551944967525778\n",
      "150/10000. noise_loss: 0.1021129799518734\n",
      "155/10000. loss: 0.3001480407714844\n",
      "155/10000. y_loss: 0.19796490035034947\n",
      "155/10000. noise_loss: 0.10218313066577538\n",
      "160/10000. loss: 0.30176244506835936\n",
      "160/10000. y_loss: 0.1981234866514569\n",
      "160/10000. noise_loss: 0.10363905863594265\n",
      "165/10000. loss: 0.29542512207031246\n",
      "165/10000. y_loss: 0.1938768104316434\n",
      "165/10000. noise_loss: 0.10154817037303002\n",
      "170/10000. loss: 0.29975885009765624\n",
      "170/10000. y_loss: 0.19848995408117773\n",
      "170/10000. noise_loss: 0.10126884845849127\n",
      "175/10000. loss: 0.30496350708007813\n",
      "175/10000. y_loss: 0.20038406470245684\n",
      "175/10000. noise_loss: 0.10457953791525217\n",
      "180/10000. loss: 0.3121666259765625\n",
      "180/10000. y_loss: 0.2051001296392409\n",
      "180/10000. noise_loss: 0.10706641783602536\n",
      "185/10000. loss: 0.30534400634765624\n",
      "185/10000. y_loss: 0.20156557999788785\n",
      "185/10000. noise_loss: 0.10377847747225313\n",
      "190/10000. loss: 0.29811462402343747\n",
      "190/10000. y_loss: 0.19739338103169576\n",
      "190/10000. noise_loss: 0.10072127904538064\n",
      "195/10000. loss: 0.29667598266601564\n",
      "195/10000. y_loss: 0.1961483135179151\n",
      "195/10000. noise_loss: 0.10052751845344901\n",
      "200/10000. loss: 0.3049647827148438\n",
      "200/10000. y_loss: 0.20172720053330995\n",
      "200/10000. noise_loss: 0.10323770747575908\n",
      "205/10000. loss: 0.2960456787109375\n",
      "205/10000. y_loss: 0.19693615609235132\n",
      "205/10000. noise_loss: 0.09910952297002076\n",
      "210/10000. loss: 0.29731443481445313\n",
      "210/10000. y_loss: 0.1971690167028457\n",
      "210/10000. noise_loss: 0.10014542228598147\n",
      "215/10000. loss: 0.3071070190429688\n",
      "215/10000. y_loss: 0.20323550943448207\n",
      "215/10000. noise_loss: 0.10387156750466672\n",
      "220/10000. loss: 0.297617236328125\n",
      "220/10000. y_loss: 0.19742343061706052\n",
      "220/10000. noise_loss: 0.10019367461428048\n",
      "225/10000. loss: 0.31202110595703125\n",
      "225/10000. y_loss: 0.20600239670532758\n",
      "225/10000. noise_loss: 0.10601876677535474\n",
      "230/10000. loss: 0.28837460327148434\n",
      "230/10000. y_loss: 0.1916097192958463\n",
      "230/10000. noise_loss: 0.0967648408293724\n",
      "235/10000. loss: 0.3041957275390625\n",
      "235/10000. y_loss: 0.20154605616144838\n",
      "235/10000. noise_loss: 0.10264979162383825\n",
      "240/10000. loss: 0.30040109252929686\n",
      "240/10000. y_loss: 0.19910904980981722\n",
      "240/10000. noise_loss: 0.10129204134270549\n",
      "245/10000. loss: 0.30070928344726566\n",
      "245/10000. y_loss: 0.19954338454115206\n",
      "245/10000. noise_loss: 0.10116598519403489\n",
      "250/10000. loss: 0.2985411437988281\n",
      "250/10000. y_loss: 0.19853533985316754\n",
      "250/10000. noise_loss: 0.10000587630644439\n",
      "255/10000. loss: 0.30622143554687503\n",
      "255/10000. y_loss: 0.20264888036302292\n",
      "255/10000. noise_loss: 0.10357254806738345\n",
      "260/10000. loss: 0.31345982666015626\n",
      "260/10000. y_loss: 0.20710920651745984\n",
      "260/10000. noise_loss: 0.10635060369540006\n",
      "265/10000. loss: 0.29232869262695316\n",
      "265/10000. y_loss: 0.19436298528090118\n",
      "265/10000. noise_loss: 0.09796567370686679\n",
      "270/10000. loss: 0.2937313903808594\n",
      "270/10000. y_loss: 0.19591335428357123\n",
      "270/10000. noise_loss: 0.09781803285814822\n",
      "275/10000. loss: 0.29598336791992186\n",
      "275/10000. y_loss: 0.19612012818222865\n",
      "275/10000. noise_loss: 0.09986328413728626\n",
      "280/10000. loss: 0.3049724426269531\n",
      "280/10000. y_loss: 0.20200398416849782\n",
      "280/10000. noise_loss: 0.10296842227857558\n",
      "285/10000. loss: 0.28609152221679685\n",
      "285/10000. y_loss: 0.19086029411531052\n",
      "285/10000. noise_loss: 0.09523127893265336\n",
      "290/10000. loss: 0.29761557617187495\n",
      "290/10000. y_loss: 0.1979391997156199\n",
      "290/10000. noise_loss: 0.09967638721019029\n",
      "295/10000. loss: 0.30332243041992185\n",
      "295/10000. y_loss: 0.2010536447323393\n",
      "295/10000. noise_loss: 0.1022686895599589\n",
      "300/10000. loss: 0.3099665771484375\n",
      "300/10000. y_loss: 0.20482267653150482\n",
      "300/10000. noise_loss: 0.10514400467369707\n",
      "305/10000. loss: 0.3004971008300782\n",
      "305/10000. y_loss: 0.19950194327188656\n",
      "305/10000. noise_loss: 0.10099520214851945\n",
      "310/10000. loss: 0.29783037719726557\n",
      "310/10000. y_loss: 0.1979695765894372\n",
      "310/10000. noise_loss: 0.0998607955865562\n",
      "315/10000. loss: 0.31126718139648435\n",
      "315/10000. y_loss: 0.20610934969726946\n",
      "315/10000. noise_loss: 0.1051579227656126\n",
      "320/10000. loss: 0.3034996765136719\n",
      "320/10000. y_loss: 0.2016521139394492\n",
      "320/10000. noise_loss: 0.10184756838511674\n",
      "325/10000. loss: 0.2953130798339844\n",
      "325/10000. y_loss: 0.19623392008030788\n",
      "325/10000. noise_loss: 0.09907919090799988\n",
      "330/10000. loss: 0.29277990112304686\n",
      "330/10000. y_loss: 0.19444361674701796\n",
      "330/10000. noise_loss: 0.09833624100629239\n",
      "335/10000. loss: 0.3030202514648438\n",
      "335/10000. y_loss: 0.20179805832328274\n",
      "335/10000. noise_loss: 0.10122211282476783\n",
      "340/10000. loss: 0.3049355407714843\n",
      "340/10000. y_loss: 0.20255770172690973\n",
      "340/10000. noise_loss: 0.10237785476408898\n",
      "345/10000. loss: 0.3153342956542969\n",
      "345/10000. y_loss: 0.20771870232452638\n",
      "345/10000. noise_loss: 0.10761565759889782\n",
      "350/10000. loss: 0.2972356079101563\n",
      "350/10000. y_loss: 0.19746013128194026\n",
      "350/10000. noise_loss: 0.0997753779694438\n",
      "355/10000. loss: 0.3067307556152344\n",
      "355/10000. y_loss: 0.2033435228298884\n",
      "355/10000. noise_loss: 0.10338714856412264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/10000. loss: 0.2902663513183594\n",
      "360/10000. y_loss: 0.1923353200821206\n",
      "360/10000. noise_loss: 0.09793103165533394\n",
      "365/10000. loss: 0.2992430053710937\n",
      "365/10000. y_loss: 0.19868253155224957\n",
      "365/10000. noise_loss: 0.10056038821376859\n",
      "370/10000. loss: 0.2844400207519531\n",
      "370/10000. y_loss: 0.19005736813335677\n",
      "370/10000. noise_loss: 0.09438267751801759\n",
      "375/10000. loss: 0.2949103210449219\n",
      "375/10000. y_loss: 0.19595385260423645\n",
      "375/10000. noise_loss: 0.0989565235702321\n",
      "380/10000. loss: 0.2967346801757812\n",
      "380/10000. y_loss: 0.1969207351332996\n",
      "380/10000. noise_loss: 0.09981397429872305\n",
      "385/10000. loss: 0.3000840881347656\n",
      "385/10000. y_loss: 0.19865505812466142\n",
      "385/10000. noise_loss: 0.10142899267598986\n",
      "390/10000. loss: 0.29992590942382813\n",
      "390/10000. y_loss: 0.1984351046252996\n",
      "390/10000. noise_loss: 0.10149067143108695\n",
      "395/10000. loss: 0.29225361938476563\n",
      "395/10000. y_loss: 0.19449964554701\n",
      "395/10000. noise_loss: 0.09775387675873935\n",
      "400/10000. loss: 0.3041015686035156\n",
      "400/10000. y_loss: 0.20184185209227726\n",
      "400/10000. noise_loss: 0.10225973802246154\n",
      "405/10000. loss: 0.2933641845703125\n",
      "405/10000. y_loss: 0.19530614278391\n",
      "405/10000. noise_loss: 0.09805800653696059\n",
      "410/10000. loss: 0.3016320007324219\n",
      "410/10000. y_loss: 0.20005502202552744\n",
      "410/10000. noise_loss: 0.10157695454619824\n",
      "415/10000. loss: 0.31195488891601564\n",
      "415/10000. y_loss: 0.20723743185903873\n",
      "415/10000. noise_loss: 0.10471741832885892\n",
      "420/10000. loss: 0.29873430786132815\n",
      "420/10000. y_loss: 0.19814534377949314\n",
      "420/10000. noise_loss: 0.10058902497813108\n",
      "425/10000. loss: 0.31547579345703125\n",
      "425/10000. y_loss: 0.2093198949130252\n",
      "425/10000. noise_loss: 0.10615576315373183\n",
      "430/10000. loss: 0.3080705200195313\n",
      "430/10000. y_loss: 0.2037256247741636\n",
      "430/10000. noise_loss: 0.10434497124087065\n",
      "435/10000. loss: 0.3014377380371093\n",
      "435/10000. y_loss: 0.1998460128008388\n",
      "435/10000. noise_loss: 0.1015916956242174\n",
      "440/10000. loss: 0.29131673583984374\n",
      "440/10000. y_loss: 0.19474007680336947\n",
      "440/10000. noise_loss: 0.0965766574960202\n",
      "445/10000. loss: 0.30788147583007813\n",
      "445/10000. y_loss: 0.20426093040863053\n",
      "445/10000. noise_loss: 0.1036206670600921\n",
      "450/10000. loss: 0.29290386352539055\n",
      "450/10000. y_loss: 0.19493436499661768\n",
      "450/10000. noise_loss: 0.09796956693595275\n",
      "455/10000. loss: 0.29910046386718747\n",
      "455/10000. y_loss: 0.19804964619236998\n",
      "455/10000. noise_loss: 0.10105078829154372\n",
      "460/10000. loss: 0.29259951171875\n",
      "460/10000. y_loss: 0.19466318231555632\n",
      "460/10000. noise_loss: 0.09793631491083651\n",
      "465/10000. loss: 0.3028260498046875\n",
      "465/10000. y_loss: 0.20087755126100965\n",
      "465/10000. noise_loss: 0.1019484630515799\n",
      "470/10000. loss: 0.29630738525390626\n",
      "470/10000. y_loss: 0.19651225601648908\n",
      "470/10000. noise_loss: 0.09979519408382476\n",
      "475/10000. loss: 0.29282817382812504\n",
      "475/10000. y_loss: 0.1947815822279081\n",
      "475/10000. noise_loss: 0.09804664555331691\n",
      "480/10000. loss: 0.31179330444335934\n",
      "480/10000. y_loss: 0.2067883054089732\n",
      "480/10000. noise_loss: 0.1050050989214331\n",
      "485/10000. loss: 0.30527153320312495\n",
      "485/10000. y_loss: 0.20247215103381314\n",
      "485/10000. noise_loss: 0.10279935535602272\n",
      "490/10000. loss: 0.31024188842773437\n",
      "490/10000. y_loss: 0.20620576684758998\n",
      "490/10000. noise_loss: 0.10403617659546435\n",
      "495/10000. loss: 0.2941831481933594\n",
      "495/10000. y_loss: 0.1958254618851468\n",
      "495/10000. noise_loss: 0.09835762987751515\n",
      "500/10000. loss: 0.3006241760253906\n",
      "500/10000. y_loss: 0.1993546314389445\n",
      "500/10000. noise_loss: 0.10126954473759979\n",
      "505/10000. loss: 0.29557287597656245\n",
      "505/10000. y_loss: 0.19633056445941327\n",
      "505/10000. noise_loss: 0.09924213541373611\n",
      "510/10000. loss: 0.29751885986328125\n",
      "510/10000. y_loss: 0.197956300477311\n",
      "510/10000. noise_loss: 0.0995624270254746\n",
      "515/10000. loss: 0.29834470214843756\n",
      "515/10000. y_loss: 0.19813095072838477\n",
      "515/10000. noise_loss: 0.10021386705860495\n",
      "520/10000. loss: 0.29972538452148434\n",
      "520/10000. y_loss: 0.19903157079024242\n",
      "520/10000. noise_loss: 0.10069385693129151\n",
      "525/10000. loss: 0.30225205688476564\n",
      "525/10000. y_loss: 0.20058377471161074\n",
      "525/10000. noise_loss: 0.10166838133502751\n",
      "530/10000. loss: 0.2862220886230469\n",
      "530/10000. y_loss: 0.19057094888105058\n",
      "530/10000. noise_loss: 0.09565119725149125\n",
      "535/10000. loss: 0.3036844482421875\n",
      "535/10000. y_loss: 0.20117692468557508\n",
      "535/10000. noise_loss: 0.10250740186944604\n",
      "540/10000. loss: 0.28773207397460937\n",
      "540/10000. y_loss: 0.1914669277734589\n",
      "540/10000. noise_loss: 0.09626517252046615\n",
      "545/10000. loss: 0.3026919982910157\n",
      "545/10000. y_loss: 0.2000084553596564\n",
      "545/10000. noise_loss: 0.10268347716555\n",
      "550/10000. loss: 0.3035328186035156\n",
      "550/10000. y_loss: 0.20111340421792118\n",
      "550/10000. noise_loss: 0.10241945740692318\n",
      "555/10000. loss: 0.3010300659179687\n",
      "555/10000. y_loss: 0.2007319368239958\n",
      "555/10000. noise_loss: 0.10029818737730385\n",
      "560/10000. loss: 0.3116759216308594\n",
      "560/10000. y_loss: 0.20505950069185347\n",
      "560/10000. noise_loss: 0.1066164457546547\n",
      "565/10000. loss: 0.29770062866210933\n",
      "565/10000. y_loss: 0.19732815724676475\n",
      "565/10000. noise_loss: 0.10037241611666978\n",
      "570/10000. loss: 0.3061061279296875\n",
      "570/10000. y_loss: 0.2022617809823714\n",
      "570/10000. noise_loss: 0.10384439064841718\n",
      "575/10000. loss: 0.2968670043945313\n",
      "575/10000. y_loss: 0.19620247488887982\n",
      "575/10000. noise_loss: 0.10066457788571717\n",
      "580/10000. loss: 0.28411076660156254\n",
      "580/10000. y_loss: 0.1887683747948613\n",
      "580/10000. noise_loss: 0.09534250770471989\n",
      "585/10000. loss: 0.3062437683105469\n",
      "585/10000. y_loss: 0.20216500669736415\n",
      "585/10000. noise_loss: 0.10407875272613018\n",
      "590/10000. loss: 0.2945656555175781\n",
      "590/10000. y_loss: 0.19567243547667748\n",
      "590/10000. noise_loss: 0.09889319889992476\n",
      "595/10000. loss: 0.2854115234375\n",
      "595/10000. y_loss: 0.19095644946377727\n",
      "595/10000. noise_loss: 0.09445509564355016\n",
      "600/10000. loss: 0.29913103027343746\n",
      "600/10000. y_loss: 0.19876401044488884\n",
      "600/10000. noise_loss: 0.10036693638768046\n",
      "605/10000. loss: 0.31257500610351563\n",
      "605/10000. y_loss: 0.2065875198144\n",
      "605/10000. noise_loss: 0.10598752959650011\n",
      "610/10000. loss: 0.2954867553710937\n",
      "610/10000. y_loss: 0.19695759806218557\n",
      "610/10000. noise_loss: 0.09852920382674785\n",
      "615/10000. loss: 0.30410353393554684\n",
      "615/10000. y_loss: 0.20255941173629838\n",
      "615/10000. noise_loss: 0.10154404610078782\n",
      "620/10000. loss: 0.3110693908691406\n",
      "620/10000. y_loss: 0.20576581289456222\n",
      "620/10000. noise_loss: 0.10530346348844469\n",
      "625/10000. loss: 0.3007571594238282\n",
      "625/10000. y_loss: 0.19913219511061905\n",
      "625/10000. noise_loss: 0.1016248980537057\n",
      "630/10000. loss: 0.2930417907714844\n",
      "630/10000. y_loss: 0.19547253701612355\n",
      "630/10000. noise_loss: 0.09756923834327609\n",
      "635/10000. loss: 0.30144418945312507\n",
      "635/10000. y_loss: 0.2006339958583005\n",
      "635/10000. noise_loss: 0.10081010330803693\n",
      "640/10000. loss: 0.3034292114257813\n",
      "640/10000. y_loss: 0.20193648330285216\n",
      "640/10000. noise_loss: 0.10149281464014201\n",
      "645/10000. loss: 0.2949770751953125\n",
      "645/10000. y_loss: 0.1963147018600255\n",
      "645/10000. noise_loss: 0.09866244721114635\n",
      "650/10000. loss: 0.30042820434570316\n",
      "650/10000. y_loss: 0.19938462814548982\n",
      "650/10000. noise_loss: 0.1010436833951622\n",
      "655/10000. loss: 0.30277432861328124\n",
      "655/10000. y_loss: 0.20069352289740924\n",
      "655/10000. noise_loss: 0.10208089041840288\n",
      "660/10000. loss: 0.2991996337890625\n",
      "660/10000. y_loss: 0.19899347851453347\n",
      "660/10000. noise_loss: 0.10020605632811785\n",
      "665/10000. loss: 0.2912315368652344\n",
      "665/10000. y_loss: 0.1936904461046681\n",
      "665/10000. noise_loss: 0.09754107175022364\n",
      "670/10000. loss: 0.3047651123046875\n",
      "670/10000. y_loss: 0.20131854900745677\n",
      "670/10000. noise_loss: 0.10344659758340566\n",
      "675/10000. loss: 0.2941917419433594\n",
      "675/10000. y_loss: 0.19591954432274214\n",
      "675/10000. noise_loss: 0.09827226712815465\n",
      "680/10000. loss: 0.30423895263671874\n",
      "680/10000. y_loss: 0.20116488281027411\n",
      "680/10000. noise_loss: 0.10307418043036014\n",
      "685/10000. loss: 0.30038963623046877\n",
      "685/10000. y_loss: 0.1993062108496204\n",
      "685/10000. noise_loss: 0.10108338201642038\n",
      "690/10000. loss: 0.2993622375488282\n",
      "690/10000. y_loss: 0.19865948904897085\n",
      "690/10000. noise_loss: 0.10070275223590433\n",
      "695/10000. loss: 0.2881350891113282\n",
      "695/10000. y_loss: 0.1913177052744664\n",
      "695/10000. noise_loss: 0.0968174971166998\n",
      "700/10000. loss: 0.29345700073242187\n",
      "700/10000. y_loss: 0.19474159827046095\n",
      "700/10000. noise_loss: 0.09871530905291438\n",
      "705/10000. loss: 0.29917224731445313\n",
      "705/10000. y_loss: 0.19870470584323632\n",
      "705/10000. noise_loss: 0.1004675327152014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710/10000. loss: 0.29161337280273436\n",
      "710/10000. y_loss: 0.1939239886483643\n",
      "710/10000. noise_loss: 0.09768950376342982\n",
      "715/10000. loss: 0.29093756713867186\n",
      "715/10000. y_loss: 0.1926042590962723\n",
      "715/10000. noise_loss: 0.09833325190208853\n",
      "720/10000. loss: 0.29304679565429687\n",
      "720/10000. y_loss: 0.19467510025659576\n",
      "720/10000. noise_loss: 0.09837174670714885\n",
      "725/10000. loss: 0.3001169860839844\n",
      "725/10000. y_loss: 0.19860780515070073\n",
      "725/10000. noise_loss: 0.1015091838981956\n",
      "730/10000. loss: 0.3035155883789062\n",
      "730/10000. y_loss: 0.20067188452258705\n",
      "730/10000. noise_loss: 0.10284371464438738\n",
      "735/10000. loss: 0.312658203125\n",
      "735/10000. y_loss: 0.2074966427822597\n",
      "735/10000. noise_loss: 0.10516165658608079\n",
      "740/10000. loss: 0.30016772460937496\n",
      "740/10000. y_loss: 0.19976110856840384\n",
      "740/10000. noise_loss: 0.10040667170342057\n",
      "745/10000. loss: 0.2990158142089844\n",
      "745/10000. y_loss: 0.19808368604788557\n",
      "745/10000. noise_loss: 0.10093219341430812\n",
      "750/10000. loss: 0.2906202758789062\n",
      "750/10000. y_loss: 0.19279583865753375\n",
      "750/10000. noise_loss: 0.09782443741876631\n",
      "755/10000. loss: 0.303392236328125\n",
      "755/10000. y_loss: 0.2013789579456672\n",
      "755/10000. noise_loss: 0.10201339824497699\n",
      "760/10000. loss: 0.3008191101074219\n",
      "760/10000. y_loss: 0.19817727353740483\n",
      "760/10000. noise_loss: 0.10264175874590875\n",
      "765/10000. loss: 0.3052827453613281\n",
      "765/10000. y_loss: 0.20205377998854965\n",
      "765/10000. noise_loss: 0.10322911166641861\n",
      "770/10000. loss: 0.2885907409667968\n",
      "770/10000. y_loss: 0.19206622321559114\n",
      "770/10000. noise_loss: 0.09652449221499264\n",
      "775/10000. loss: 0.3071992736816406\n",
      "775/10000. y_loss: 0.20357972108274697\n",
      "775/10000. noise_loss: 0.1036195199932903\n",
      "780/10000. loss: 0.28899096069335933\n",
      "780/10000. y_loss: 0.19305787728382273\n",
      "780/10000. noise_loss: 0.09593311766488477\n",
      "785/10000. loss: 0.30564227905273433\n",
      "785/10000. y_loss: 0.20334671841394156\n",
      "785/10000. noise_loss: 0.10229561545122416\n",
      "790/10000. loss: 0.2984913452148437\n",
      "790/10000. y_loss: 0.19856942188497634\n",
      "790/10000. noise_loss: 0.09992195696029813\n",
      "795/10000. loss: 0.2930806091308594\n",
      "795/10000. y_loss: 0.19472424014066345\n",
      "795/10000. noise_loss: 0.09835635655168444\n",
      "800/10000. loss: 0.30323587646484373\n",
      "800/10000. y_loss: 0.2019472284116782\n",
      "800/10000. noise_loss: 0.1012886454185471\n",
      "805/10000. loss: 0.30592115478515625\n",
      "805/10000. y_loss: 0.2027984363399446\n",
      "805/10000. noise_loss: 0.10312270852942021\n",
      "810/10000. loss: 0.29054443359375004\n",
      "810/10000. y_loss: 0.19330195952667856\n",
      "810/10000. noise_loss: 0.09724231502227484\n",
      "815/10000. loss: 0.304290087890625\n",
      "815/10000. y_loss: 0.20148935400513\n",
      "815/10000. noise_loss: 0.10280066635534169\n",
      "820/10000. loss: 0.29449613647460937\n",
      "820/10000. y_loss: 0.19518368858331817\n",
      "820/10000. noise_loss: 0.09931255798004568\n",
      "825/10000. loss: 0.29109833984375\n",
      "825/10000. y_loss: 0.19286968315439298\n",
      "825/10000. noise_loss: 0.09822858943436294\n",
      "830/10000. loss: 0.3072737060546875\n",
      "830/10000. y_loss: 0.20343824726301243\n",
      "830/10000. noise_loss: 0.10383551583457737\n",
      "835/10000. loss: 0.30667853393554695\n",
      "835/10000. y_loss: 0.20230527840941215\n",
      "835/10000. noise_loss: 0.10437329452056436\n",
      "840/10000. loss: 0.30132243041992185\n",
      "840/10000. y_loss: 0.1987126085324213\n",
      "840/10000. noise_loss: 0.10260980266146362\n",
      "845/10000. loss: 0.2922707214355469\n",
      "845/10000. y_loss: 0.19460086137312466\n",
      "845/10000. noise_loss: 0.0976698970289901\n",
      "850/10000. loss: 0.303457080078125\n",
      "850/10000. y_loss: 0.2022757963966578\n",
      "850/10000. noise_loss: 0.10118129731863738\n",
      "855/10000. loss: 0.2993146118164063\n",
      "855/10000. y_loss: 0.19820067069842479\n",
      "855/10000. noise_loss: 0.10111400849260391\n",
      "860/10000. loss: 0.29632202148437503\n",
      "860/10000. y_loss: 0.19664166449182668\n",
      "860/10000. noise_loss: 0.09968048176020386\n",
      "865/10000. loss: 0.2954453918457031\n",
      "865/10000. y_loss: 0.19610449894419874\n",
      "865/10000. noise_loss: 0.09934087456483395\n",
      "870/10000. loss: 0.3024013305664063\n",
      "870/10000. y_loss: 0.1998541943105869\n",
      "870/10000. noise_loss: 0.1025471483282745\n",
      "875/10000. loss: 0.3040091430664063\n",
      "875/10000. y_loss: 0.2017029146471061\n",
      "875/10000. noise_loss: 0.10230631485339255\n",
      "880/10000. loss: 0.2980575134277344\n",
      "880/10000. y_loss: 0.19794540991596876\n",
      "880/10000. noise_loss: 0.10011208742149173\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b6035b3ee819>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-b6035b3ee819>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSine_Task_Distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mmaml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMAML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAMLModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mmaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;31m# save the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'models/model_30_10000.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/mila/uncertainty/meta_learning/meta_training_noisy.py\u001b[0m in \u001b[0;36mmain_loop\u001b[0;34m(self, num_iterations)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_per_meta_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m                 \u001b[0mmeta_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0mmeta_mean_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/mila/uncertainty/meta_learning/meta_training_noisy.py\u001b[0m in \u001b[0;36minner_loop\u001b[0;34m(self, task)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mmean_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameterised\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK\u001b[0m \u001b[0;31m# kind of training loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0msigma_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameterised\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameterised\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK\u001b[0m \u001b[0;31m# kind of training loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mfinal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmean_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msigma_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Oct  3 19:36:48 2019\n",
    "\n",
    "@author: debjani\n",
    "\"\"\"\n",
    "############Import required functions##########################################\n",
    "import torch\n",
    "import numpy as np\n",
    "from network_noisy import MAMLModel\n",
    "from meta_training_noisy import MAML\n",
    "from src.sine_tasks_uncertainty import Sine_Task_Distribution\n",
    "###############################################################################\n",
    "def main():\n",
    "    \n",
    "    #sample tasks\n",
    "    tasks = Sine_Task_Distribution(0.1, 5, 0, np.pi, -5, 5, 0, np.pi)\n",
    "    maml = MAML(MAMLModel(), tasks, inner_lr=0.001, meta_lr=0.001)\n",
    "    maml.main_loop(num_iterations=10000)\n",
    "    # save the model\n",
    "    torch.save(maml.model.state_dict(), 'models/model_30_10000.pth')\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'maml' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-58ed191c82b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'maml' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(maml.meta_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
